# Udacity-CNN-self-driving-car
An end-to-end self-driving car project developed for the Udacity simulator (Udacity_self_driving_car_nanodegree_program) using Convolutional Neural Networks (CNNs). The model predicts steering angles—and in extended versions, throttle—from only raw front-facing camera images.  
This project focuses on the experimental deployment of a convolutional neural network (CNN)-based autonomous vehicle in the Udacity Self-Driving Car Simulator. The whole development process includes data collection through manual driving, preprocessing and data augmentation of gathered images, designing and training multiple CNN models, and integrating the learned models into the simulator in auto mode. In total, four models were developed: three specialized CNN models hand-tailored from scratch, and one additional model set up by fine-tuning a pre-trained network on ResNet50. The models learned to predict the steering angle from images received from front-facing cameras and were tested on both Track 1 and Track 2 of the simulator. The best-performing model demonstrated clean, collision-free driving on both tracks, and the remaining models passed Track 1 but failed at a specific declining turn on Track 2. Comparative study of the models was also part of this project in an effort to justify the ultimate selection based on performance and theoretical explanation.
## Data Collection and Preprocessing
Data was collected by manually driving the car in training mode. The car was driven in both tracks, in the first track to cover slight turns, and straight paths, in the second track to cover rather sharp turns, and inclinations. The car was driven to remain on the drivable path without any emphasis on lane discipline, as the objective of the project is to drive the car without collisions.
The simulator outputs a sequence of 320*160 images named left, center, right, and a CSV file including paths for those images, steering angle, throttle, brake, and speed. 

